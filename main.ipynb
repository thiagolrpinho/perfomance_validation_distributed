{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T21:06:43.008533Z",
     "start_time": "2020-04-03T21:06:42.933230Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer, CountVectorizer, StopWordsRemover, StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "def create_session():\n",
    "    ''' Function used to instantiate a pySpark Session with \n",
    "    the specific configurations'''\n",
    "    sc_conf = SparkConf()\n",
    "    sc_conf.setAppName('SparkPreProcessing')\n",
    "    sc_conf.setMaster('local')\n",
    "    sc_conf.set('spark.executor.memory', '6g')\n",
    "    sc_conf.set('spark.executor.cores', '8')\n",
    "    sc_conf.set('spark.logConf', True)\n",
    "    print(sc_conf.getAll())\n",
    "    sc = SparkContext.getOrCreate(conf=sc_conf)\n",
    "    ss = SparkSession(sc)\n",
    "    return ss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. PySpark\n",
    "\n",
    "## 1.1 Loading Files and Creating Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T21:06:45.894537Z",
     "start_time": "2020-04-03T21:06:43.010544Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('spark.executor.memory', '6g'), ('spark.master', 'local'), ('spark.logConf', 'True'), ('spark.submit.deployMode', 'client'), ('spark.executor.cores', '8'), ('spark.ui.showConsoleProgress', 'true'), ('spark.app.name', 'SparkPreProcessing')]\n",
      "root\n",
      " |-- process_class: string (nullable = true)\n",
      " |-- process_id: string (nullable = true)\n",
      " |-- doc_id: string (nullable = true)\n",
      " |-- path_img: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- doc_type: string (nullable = true)\n",
      " |-- num_pag: long (nullable = true)\n",
      "\n",
      "None\n",
      "CPU times: user 28.3 ms, sys: 3.14 ms, total: 31.4 ms\n",
      "Wall time: 2.76 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Parquet files are self-describing so the schema is preserved.\n",
    "# The result of loading a parquet file is also a DataFrame.\n",
    "RELATIVE_FOLDER_PATH = \"assets/data/\"\n",
    "filename = \"data\"\n",
    "pyspark_session = create_session()\n",
    "\n",
    "ailab_df = pyspark_session.read.parquet(RELATIVE_FOLDER_PATH +\"/data.parquet.gzip\")\n",
    "print(ailab_df.printSchema())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Preprocessing and Vectorizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T21:06:56.727776Z",
     "start_time": "2020-04-03T21:06:45.896642Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+---------+--------------------+--------------------+--------------------+-------+--------------------+----------------------+--------------------+--------------------+-----+\n",
      "|process_class|process_id|   doc_id|            path_img|                text|            doc_type|num_pag|              tokens|stopWordsRemovedTokens|         rawFeatures|            features|label|\n",
      "+-------------+----------+---------+--------------------+--------------------+--------------------+-------+--------------------+----------------------+--------------------+--------------------+-----+\n",
      "|           RE|   1004784|310550039|[./processos_imgs...| Documento digita...|despacho_de_admis...|      3|[, documento, dig...|  [, documento, dig...|(2000,[15,17,20,2...|(2000,[15,17,20,2...|  1.0|\n",
      "+-------------+----------+---------+--------------------+--------------------+--------------------+-------+--------------------+----------------------+--------------------+--------------------+-----+\n",
      "only showing top 1 row\n",
      "\n",
      "CPU times: user 79.8 ms, sys: 19.9 ms, total: 99.7 ms\n",
      "Wall time: 10.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ailab_df.cache().count()\n",
    "\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"tokens\")\n",
    "remover = StopWordsRemover(inputCol=\"tokens\", outputCol=\"stopWordsRemovedTokens\")\n",
    "hashingTF = HashingTF(inputCol=\"stopWordsRemovedTokens\", outputCol=\"rawFeatures\", numFeatures=2000)\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\", minDocFreq=5)\n",
    "label_stringIdx = StringIndexer(inputCol = \"process_class\", outputCol = \"label\")\n",
    "\n",
    "pre_processing_pipeline = Pipeline(stages=[tokenizer, remover, hashingTF, idf, label_stringIdx])\n",
    "\n",
    "pre_processing_pipeline_model = pre_processing_pipeline.fit(ailab_df)\n",
    "\n",
    "treated_df = pre_processing_pipeline_model.transform(ailab_df)\n",
    "\n",
    "treated_df.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Clusterizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T21:07:10.151595Z",
     "start_time": "2020-04-03T21:06:56.730071Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+---------+--------------------+--------------------+--------------------+-------+--------------------+----------------------+--------------------+--------------------+-----+----------+\n",
      "|process_class|process_id|   doc_id|            path_img|                text|            doc_type|num_pag|              tokens|stopWordsRemovedTokens|         rawFeatures|            features|label|prediction|\n",
      "+-------------+----------+---------+--------------------+--------------------+--------------------+-------+--------------------+----------------------+--------------------+--------------------+-----+----------+\n",
      "|           RE|   1004784|310550039|[./processos_imgs...| Documento digita...|despacho_de_admis...|      3|[, documento, dig...|  [, documento, dig...|(2000,[15,17,20,2...|(2000,[15,17,20,2...|  1.0|         1|\n",
      "+-------------+----------+---------+--------------------+--------------------+--------------------+-------+--------------------+----------------------+--------------------+--------------------+-----+----------+\n",
      "only showing top 1 row\n",
      "\n",
      "CPU times: user 14 ms, sys: 7.25 ms, total: 21.3 ms\n",
      "Wall time: 13.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "kmeans = KMeans(k=20)\n",
    "kmeans_trained_model = kmeans.fit(treated_df)\n",
    "kmeans_result_df = kmeans_trained_model.transform(treated_df)\n",
    "kmeans_result_df.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Classifying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T21:07:37.432143Z",
     "start_time": "2020-04-03T21:07:10.159214Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+-------------+------------------------------+-----+----------+\n",
      "|                          text|process_class|                   probability|label|prediction|\n",
      "+------------------------------+-------------+------------------------------+-----+----------+\n",
      "| OAB/RS 0882\n",
      "\n",
      "LACERDA 6 JAC...|          ARE|[0.9982459593595978,0.00124...|  0.0|       0.0|\n",
      "| SEÇÃO V\n",
      "Da Execução\n",
      "\n",
      "Art. ...|          ARE|[0.9973522878312651,0.00200...|  0.0|       0.0|\n",
      "|  HOFFMANN\n",
      "\n",
      " \n",
      "\n",
      "ADVOGADOÇSÇS...|          ARE|[0.9923195606782952,0.00594...|  0.0|       0.0|\n",
      "| seus inimigos. É isto que ...|          ARE|[0.9923172708770535,0.00458...|  0.0|       0.0|\n",
      "| Documento recebido eletron...|          ARE|[0.9904962761549694,0.00875...|  0.0|       0.0|\n",
      "| Esso\n",
      "MARCOS III NOVAES MAR...|           RE|[0.9848453619196611,0.01268...|  1.0|       0.0|\n",
      "| ESTADO DE SANTA CATARINA\n",
      "P...|          ARE|[0.9844945094248899,0.01347...|  0.0|       0.0|\n",
      "| A\n",
      "\n",
      "jce.j i 1652-62.2010.8....|          ARE|[0.9835263282232944,0.01460...|  0.0|       0.0|\n",
      "| da Constituição Federal) e...|          ARE|[0.9814514274001014,0.01664...|  0.0|       0.0|\n",
      "| Rua Lauro Linhares, 1974 +...|          ARE|[0.9807679551280306,0.01746...|  0.0|       0.0|\n",
      "+------------------------------+-------------+------------------------------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n",
      "CPU times: user 30.5 ms, sys: 7.99 ms, total: 38.5 ms\n",
      "Wall time: 27.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "(trainingData, testData) = treated_df.randomSplit([0.7, 0.3], seed = 100)\n",
    "lr = LogisticRegression(maxIter=20, regParam=0.3, elasticNetParam=0)\n",
    "lrModel = lr.fit(trainingData)\n",
    "predictions = lrModel.transform(testData)\n",
    "predictions.filter(predictions['prediction'] == 0) \\\n",
    "    .select(\"text\",\"process_class\",\"probability\",\"label\",\"prediction\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T21:08:14.166849Z",
     "start_time": "2020-04-03T21:07:37.435768Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.55 ms, sys: 849 µs, total: 10.4 ms\n",
      "Wall time: 36.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7459806286135295"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T21:08:14.266541Z",
     "start_time": "2020-04-03T21:08:14.169776Z"
    }
   },
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
