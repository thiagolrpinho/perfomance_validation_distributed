{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T20:22:18.343691Z",
     "start_time": "2020-04-03T20:22:17.320482Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer, CountVectorizer, StopWordsRemover, StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.clustering import KMeans\n",
    "\n",
    "def create_session():\n",
    "    sc_conf = SparkConf()\n",
    "    sc_conf.setAppName('SparkPreProcessing')\n",
    "    sc_conf.setMaster('local')\n",
    "    sc_conf.set('spark.executor.memory', '6g')\n",
    "    sc_conf.set('spark.executor.cores', '8')\n",
    "    sc_conf.set('spark.logConf', True)\n",
    "    print(sc_conf.getAll())\n",
    "    sc = SparkContext.getOrCreate(conf=sc_conf)\n",
    "    ss = SparkSession(sc)\n",
    "    return ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T20:30:17.546460Z",
     "start_time": "2020-04-03T20:30:17.428278Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('spark.executor.memory', '6g'), ('spark.master', 'local'), ('spark.logConf', 'True'), ('spark.submit.deployMode', 'client'), ('spark.executor.cores', '8'), ('spark.ui.showConsoleProgress', 'true'), ('spark.app.name', 'SparkPreProcessing')]\n",
      "root\n",
      " |-- process_class: string (nullable = true)\n",
      " |-- process_id: string (nullable = true)\n",
      " |-- doc_id: string (nullable = true)\n",
      " |-- path_img: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- doc_type: string (nullable = true)\n",
      " |-- num_pag: long (nullable = true)\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Parquet files are self-describing so the schema is preserved.\n",
    "# The result of loading a parquet file is also a DataFrame.\n",
    "RELATIVE_FOLDER_PATH = \"assets/data/\"\n",
    "filename = \"data\"\n",
    "sc = create_session()\n",
    "\n",
    "ailab_df = sc.read.parquet(RELATIVE_FOLDER_PATH +\"/data.parquet.gzip\")\n",
    "print(ailab_df.printSchema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T20:52:19.266407Z",
     "start_time": "2020-04-03T20:52:12.847439Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+---------+--------------------+--------------------+--------------------+-------+--------------------+----------------------+--------------------+--------------------+-----+\n",
      "|process_class|process_id|   doc_id|            path_img|                text|            doc_type|num_pag|              tokens|stopWordsRemovedTokens|         rawFeatures|            features|label|\n",
      "+-------------+----------+---------+--------------------+--------------------+--------------------+-------+--------------------+----------------------+--------------------+--------------------+-----+\n",
      "|           RE|   1004784|310550039|[./processos_imgs...| Documento digita...|despacho_de_admis...|      3|[, documento, dig...|  [, documento, dig...|(2000,[15,17,20,2...|(2000,[15,17,20,2...|  1.0|\n",
      "+-------------+----------+---------+--------------------+--------------------+--------------------+-------+--------------------+----------------------+--------------------+--------------------+-----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ailab_df.cache().count()\n",
    "\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"tokens\")\n",
    "remover = StopWordsRemover(inputCol=\"tokens\", outputCol=\"stopWordsRemovedTokens\")\n",
    "hashingTF = HashingTF(inputCol=\"stopWordsRemovedTokens\", outputCol=\"rawFeatures\", numFeatures=2000)\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\", minDocFreq=5)\n",
    "label_stringIdx = StringIndexer(inputCol = \"process_class\", outputCol = \"label\")\n",
    "\n",
    "pre_processing_pipeline = Pipeline(stages=[tokenizer, remover, hashingTF, idf, label_stringIdx])\n",
    "\n",
    "pre_processing_pipeline_model = pre_processing_pipeline.fit(ailab_df)\n",
    "\n",
    "treated_df = pre_processing_pipeline_model.transform(ailab_df)\n",
    "\n",
    "treated_df.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T20:53:44.905777Z",
     "start_time": "2020-04-03T20:53:30.723103Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+---------+--------------------+--------------------+--------------------+-------+--------------------+----------------------+--------------------+--------------------+-----+----------+\n",
      "|process_class|process_id|   doc_id|            path_img|                text|            doc_type|num_pag|              tokens|stopWordsRemovedTokens|         rawFeatures|            features|label|prediction|\n",
      "+-------------+----------+---------+--------------------+--------------------+--------------------+-------+--------------------+----------------------+--------------------+--------------------+-----+----------+\n",
      "|           RE|   1004784|310550039|[./processos_imgs...| Documento digita...|despacho_de_admis...|      3|[, documento, dig...|  [, documento, dig...|(2000,[15,17,20,2...|(2000,[15,17,20,2...|  1.0|        11|\n",
      "+-------------+----------+---------+--------------------+--------------------+--------------------+-------+--------------------+----------------------+--------------------+--------------------+-----+----------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kmeans = KMeans(k=20)\n",
    "kmeans_trained_model = kmeans.fit(treated_df)\n",
    "kmeans_result_df = kmeans_trained_model.transform(treated_df)\n",
    "kmeans_result_df.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T20:54:36.354567Z",
     "start_time": "2020-04-03T20:54:01.829380Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+-------------+------------------------------+-----+----------+\n",
      "|                          text|process_class|                   probability|label|prediction|\n",
      "+------------------------------+-------------+------------------------------+-----+----------+\n",
      "| i\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "  ...|          ARE|[0.9999932589578077,3.97377...|  0.0|       0.0|\n",
      "| SEÇÃO V\n",
      "Da Execução\n",
      "\n",
      "Art. ...|          ARE|[0.9992210908220771,4.54681...|  0.0|       0.0|\n",
      "| Rodrigues dos Santos & Sou...|           RE|[0.9904324939584316,0.00632...|  1.0|       0.0|\n",
      "| IXA\n",
      "\n",
      "privada, não é razoáv...|          ARE|[0.9887038042609323,0.01085...|  0.0|       0.0|\n",
      "| JUNTADA\n",
      "junto aos presente...|          ARE|[0.9851287444111012,0.01310...|  0.0|       0.0|\n",
      "| mxl o\n",
      "\n",
      "ADVOC\n",
      "\n",
      "MARCATTO\n",
      "\n",
      "se...|          ARE|[0.9836183978290796,0.01266...|  0.0|       0.0|\n",
      "| ESTADO DE SANTA CATARINA J...|          ARE|[0.9818315239268227,0.01594...|  0.0|       0.0|\n",
      "| fis. 155\n",
      "\n",
      "ESTADO DE SANTA ...|          ARE|[0.9800130632420322,0.01802...|  0.0|       0.0|\n",
      "| fis. 151\n",
      "\n",
      "ESTADO DE SANTA ...|          ARE|[0.9785899451018625,0.01930...|  0.0|       0.0|\n",
      "| ESTADO DE SANTA CATARINA J...|          ARE|[0.9767300696452298,0.02106...|  0.0|       0.0|\n",
      "+------------------------------+-------------+------------------------------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(trainingData, testData) = treated_df.randomSplit([0.7, 0.3], seed = 100)\n",
    "lr = LogisticRegression(maxIter=20, regParam=0.3, elasticNetParam=0)\n",
    "lrModel = lr.fit(trainingData)\n",
    "predictions = lrModel.transform(testData)\n",
    "predictions.filter(predictions['prediction'] == 0) \\\n",
    "    .select(\"text\",\"process_class\",\"probability\",\"label\",\"prediction\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T20:57:04.833769Z",
     "start_time": "2020-04-03T20:56:16.414640Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7279028242295433"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
